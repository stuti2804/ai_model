import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder, StandardScaler
import joblib

# âœ… Load dataset
df = pd.read_csv("data/train.csv")

# âœ… Check missing values before handling
print("Missing values before handling:\n", df.isnull().sum())

# âœ… Separate numeric and categorical columns
numeric_cols = ['Systolic BP', 'Diastolic', 'BS', 'BMI', 'Heart Rate']
categorical_cols = ['Previous Complications', 'Preexisting Diabetes', 'Gestational Diabetes', 'Mental Health', 'Risk Level']

# âœ… Fill missing values in numeric columns with median
df[numeric_cols] = df[numeric_cols].apply(lambda x: x.fillna(x.median()))

# âœ… Fill missing values in categorical columns with mode (most frequent value)
df[categorical_cols] = df[categorical_cols].apply(lambda x: x.fillna(x.mode()[0]))

# âœ… Drop rows where 'Risk Level' is still missing
df = df.dropna(subset=['Risk Level'])

# âœ… Encode categorical target variable (ONLY "Low" and "High")
risk_mapping = {"Low": 0, "High": 1}
df = df[df["Risk Level"].isin(risk_mapping)]  # Remove any unexpected classes
df["Risk Level"] = df["Risk Level"].map(risk_mapping)

# âœ… Verify unique classes
print("\nðŸŸ¢ Unique Risk Levels in Dataset:", df["Risk Level"].unique())

# âœ… Split features and target
X = df.drop(columns=['Risk Level'])
y = df['Risk Level']

# âœ… Train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# âœ… Feature Scaling
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# âœ… Train model with optimized parameters
model = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=42)
model.fit(X_train_scaled, y_train)

# âœ… Model Predictions
y_pred = model.predict(X_test_scaled)

# âœ… Evaluate model
accuracy = accuracy_score(y_test, y_pred)
print(f"\nâœ… Model Accuracy: {accuracy:.2f}")
print("\nðŸ“Š Classification Report:\n", classification_report(y_test, y_pred, target_names=["Low", "High"]))

# âœ… Ensure the directory exists before saving
model_dir = "ai_model"
os.makedirs(model_dir, exist_ok=True)  # Create directory if it doesn't exist

# âœ… Save the trained model & scaler
joblib.dump(model, os.path.join(model_dir, "pregnancy_risk_model.pkl"))
joblib.dump(scaler, os.path.join(model_dir, "scaler.pkl"))

print("\nâœ… Model and Scaler saved successfully!")